import os
import re
import shutil
import subprocess
import logging
import uuid
import time
import pandas as pd
import numpy as np
from pathlib import Path
import imageio_ffmpeg
import gradio as gr
import sys
import gc
import threading

# ==========================================
# ×—×œ×§ 0: ×ª×™×§×•×Ÿ ××’×¨×¡×™×‘×™ ×œ×“×¨×™×™×‘×¨×™×
# ==========================================
def force_cudnn_path():
    try:
        import torch
        torch_lib = os.path.join(os.path.dirname(torch.__file__), 'lib')
        if os.path.exists(torch_lib):
            os.environ['PATH'] = torch_lib + os.pathsep + os.environ['PATH']
            if hasattr(os, 'add_dll_directory'):
                os.add_dll_directory(torch_lib)
    except: pass

force_cudnn_path()

# ==========================================
# ×—×œ×§ 1: × ×™×”×•×œ ××©××‘×™×
# ==========================================

WORK_DIR = os.path.abspath("Karaoke_Output")
os.makedirs(WORK_DIR, exist_ok=True)

try:
    import torch
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ ×—×•××¨×” ×–×•×”×ª×”: {torch.cuda.get_device_name(0) if DEVICE == 'cuda' else 'CPU'}")
except ImportError:
    DEVICE = "cpu"

class ResourceManager:
    def __init__(self, max_concurrent_heavy=2):
        self.semaphore = threading.Semaphore(max_concurrent_heavy)
        self.active_tasks = 0
        self.lock = threading.Lock()

    def get_status(self):
        with self.lock:
            active = self.active_tasks
        
        mem_info = ""
        if DEVICE == "cuda":
            try:
                free_mem, total_mem = torch.cuda.mem_get_info()
                free_gb = free_mem / 1024**3
                mem_info = f"(VRAM ×¤× ×•×™: {free_gb:.1f}GB)"
                if free_gb < 4: return f"ğŸ”´ ×¢×•××¡ ×’×‘×•×” ×××•×“ {mem_info} - ×××ª×™×Ÿ..."
            except: pass
        
        if active == 0: return f"ğŸŸ¢ ×¤× ×•×™ ×œ×”×•×¨××•×ª {mem_info}"
        if active == 1: return f"ğŸŸ¢ ×¢×•×‘×“ (××©×™××” 1) {mem_info}"
        if active >= 2: return f"ğŸŸ  ×¢××•×¡ (2 ××©×™××•×ª) {mem_info}"
        return "Unknown"

    def start_task(self):
        with self.lock:
            self.active_tasks += 1

    def end_task(self):
        with self.lock:
            self.active_tasks -= 1

manager = ResourceManager(max_concurrent_heavy=2)

# ==========================================
# ×—×œ×§ 2: ×× ×•×¢ ×”×¢×™×‘×•×“ (Backend)
# ==========================================

try:
    import yt_dlp
    import soundfile as sf
    from transformers import pipeline
    from audio_separator.separator import Separator
    import librosa
    import arabic_reshaper
    from bidi.algorithm import get_display
except ImportError as e:
    print(f"âŒ ×©×’×™××”: ×—×¡×¨×•×ª ×¡×¤×¨×™×•×ª ({e}).")

logging.getLogger("audio_separator").setLevel(logging.ERROR)
logging.getLogger("transformers").setLevel(logging.ERROR)

class BackendProcessor:
    def __init__(self):
        self.ffmpeg_exe = imageio_ffmpeg.get_ffmpeg_exe()

    def log(self, msg, log_list=None):
        ts = time.strftime("%H:%M:%S")
        formatted_msg = f"[{ts}] {msg}"
        print(formatted_msg)
        if log_list is not None:
            log_list.append(formatted_msg)
        return formatted_msg

    def cleanup_resources(self):
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        gc.collect()

    def _fix_hebrew_text(self, text):
        try:
            if not text: return ""
            text = str(text)
            reshaped = arabic_reshaper.reshape(text)
            return get_display(reshaped)
        except: return text

    def _sanitize_filename(self, name):
        name = re.sub(r'[\\/*?:"<>|]', '', name)
        name = name.replace("'", "").replace('"', "")
        name = name.strip().rstrip('.')
        if not name: name = f"Video_{int(time.time())}"
        return name

    def _fmt_ass_time(self, seconds):
        try:
            seconds = float(seconds)
            h = int(seconds // 3600)
            m = int((seconds % 3600) // 60)
            s = int(seconds % 60)
            cs = int((seconds - int(seconds)) * 100)
            return f"{h}:{m:02d}:{s:02d}.{cs:02d}"
        except: return "0:00:00.00"

    def convert_to_wav(self, input_path, output_path):
        try:
            cmd = [self.ffmpeg_exe, '-y', '-i', input_path, '-ar', '16000', '-ac', '1', '-c:a', 'pcm_s16le', output_path]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=60)
            return True
        except: return False

    def get_video_info(self, query, current_logs):
        search_query = query
        if not query.startswith("http"):
            search_query = f"ytsearch1:{query}"
            self.log(f"ğŸ” ××—×¤×©: '{query}'...", current_logs)
        else:
            self.log(f"ğŸ” ×× ×ª×—: '{query}'...", current_logs)
        
        opts = {'quiet': True, 'no_warnings': True, 'noplaylist': True}
        try:
            with yt_dlp.YoutubeDL(opts) as ydl:
                info = ydl.extract_info(search_query, download=False)
                if 'entries' in info:
                    if len(info['entries']) > 0: info = info['entries'][0]
                    else:
                        self.log("âŒ ×œ× × ××¦××• ×ª×•×¦××•×ª.", current_logs)
                        return None
                
                title = info.get('title', 'Unknown')
                video_id = info.get('id')
                real_url = info.get('webpage_url') or info.get('url')
                if not real_url or "googlevideo" in real_url: 
                    real_url = f"https://www.youtube.com/watch?v={video_id}"
                
                clean_title = self._sanitize_filename(title)
                if not clean_title: clean_title = f"Video_{video_id}"
                
                self.log(f"âœ… ×–×•×”×”: {clean_title}", current_logs)
                song_folder = os.path.join(WORK_DIR, clean_title)
                return {'title': clean_title, 'url': real_url, 'id': video_id, 'folder': song_folder}
        except Exception as e:
            self.log(f"âš ï¸ ×©×’×™××”: {e}", current_logs)
            return None

    def download_video(self, video_info, current_logs):
        folder = video_info['folder']
        title = video_info['title']
        url = video_info['url']
        os.makedirs(folder, exist_ok=True)
        target_path = os.path.join(folder, f"{title}.mp4")
        if os.path.exists(target_path):
            self.log(f"âœ… ×§×•×‘×¥ ××§×•×¨ ×§×™×™×.", current_logs)
            return target_path
        
        self.log(f"ğŸ“¥ ××•×¨×™×“: {url}", current_logs)
        temp_path_tmpl = os.path.join(folder, f"temp_dl_{uuid.uuid4().hex[:6]}.%(ext)s")
        opts = {'outtmpl': temp_path_tmpl, 'quiet': True, 'no_warnings': True, 'noplaylist': True, 'ffmpeg_location': self.ffmpeg_exe, 'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best', 'merge_output_format': 'mp4'}
        try:
            with yt_dlp.YoutubeDL(opts) as ydl:
                ydl.download([url])
                found = None
                for f in os.listdir(folder):
                    if f.startswith("temp_dl"): found = os.path.join(folder, f); break
                if found:
                    if os.path.exists(target_path): os.remove(target_path)
                    shutil.move(found, target_path)
                    return target_path
                return None
        except Exception as e:
            self.log(f"âŒ ×©×’×™××” ×‘×”×•×¨×“×”: {e}", current_logs); return None

    # --- ×¤×¢×•×œ×•×ª ×›×‘×“×•×ª ---
    def separate_audio(self, video_path, output_folder, current_logs, mode="2_stems", save_4=False, force=False):
        title = Path(video_path).stem
        final_vocals = os.path.join(output_folder, f"{title}_Vocals.wav")
        final_playback = os.path.join(output_folder, f"{title}_Playback.wav")
        
        should_process = True
        if os.path.exists(final_vocals) and os.path.exists(final_playback) and not force:
            try:
                temp_check = os.path.join(output_folder, f"temp_check_{uuid.uuid4().hex}.wav")
                self.convert_to_wav(video_path, temp_check)
                if os.path.exists(temp_check):
                    src_size = os.path.getsize(temp_check)
                    pb_size = os.path.getsize(final_playback)
                    os.remove(temp_check)
                    if abs(src_size - pb_size) < 1024: 
                        self.log("âš ï¸ ×–×•×”×” ×¤×œ×™×™×‘×§ ×¤×’×•×. ××‘×¦×¢ ×”×¤×¨×“×” ××—×“×©...", current_logs)
                        should_process = True
                    else:
                        self.log(f"âœ… ×§×‘×¦×™ ×”×¤×¨×“×” ×ª×§×™× ×™× ×§×™×™××™×.", current_logs)
                        should_process = False
                else: should_process = True 
            except: should_process = True 

        if not should_process: return final_vocals, final_playback
        
        if force:
            self.log("â™»ï¸ ××‘×¦×¢ ×›×¤×™×™×ª ×¢×™×‘×•×“ ××—×“×©...", current_logs)
            if os.path.exists(final_vocals): os.remove(final_vocals)
            if os.path.exists(final_playback): os.remove(final_playback)

        self.log("â³ ×××ª×™×Ÿ ×œ××©××‘×™ ××¢×¨×›×ª...", current_logs)
        with manager.semaphore:
            manager.start_task()
            try:
                self.log("ğŸš€ ××ª×—×™×œ ×”×¤×¨×“×”...", current_logs)
                self.cleanup_resources()
                
                sep_temp_dir = os.path.join(output_folder, f"temp_sep_{uuid.uuid4().hex[:6]}")
                os.makedirs(sep_temp_dir, exist_ok=True)
                
                input_wav = os.path.join(sep_temp_dir, "input.wav")
                self.convert_to_wav(video_path, input_wav)

                sep = Separator(log_level=logging.ERROR, output_dir=sep_temp_dir, model_file_dir=os.path.join(WORK_DIR, "uvr_models"))
                sep.load_model("Kim_Vocal_2.onnx")
                files = sep.separate(input_wav)
                
                for f in files:
                    src = os.path.join(sep_temp_dir, f)
                    lower = f.lower()
                    if ("vocal" in lower) and ("no" not in lower) and ("inst" not in lower): shutil.move(src, final_vocals)
                    elif ("instrumental" in lower) or ("no_vocals" in lower): shutil.move(src, final_playback)
                
                del sep
                self.cleanup_resources()

                if save_4 and os.path.exists(input_wav):
                    self.log(f"ğŸšï¸ ××¤×¨×™×“ ×œ-4 ×¢×¨×•×¦×™×...", current_logs)
                    sep4 = Separator(log_level=logging.ERROR, output_dir=sep_temp_dir)
                    sep4.load_model("htdemucs_ft.yaml")
                    files4 = sep4.separate(input_wav)
                    for f in files4:
                        src = os.path.join(sep_temp_dir, f)
                        dest = os.path.join(output_folder, f"{title}_{f}")
                        if "drums" in f.lower(): dest = os.path.join(output_folder, f"{title}_Drums.wav")
                        elif "bass" in f.lower(): dest = os.path.join(output_folder, f"{title}_Bass.wav")
                        elif "vocals" in f.lower(): dest = os.path.join(output_folder, f"{title}_Vocals_Demucs.wav")
                        elif "other" in f.lower(): dest = os.path.join(output_folder, f"{title}_Other.wav")
                        shutil.move(src, dest)
                    del sep4
                    self.cleanup_resources()

                if os.path.exists(sep_temp_dir): shutil.rmtree(sep_temp_dir)
                return final_vocals, final_playback

            except Exception as e:
                self.log(f"âŒ ×©×’×™××” ×‘×”×¤×¨×“×”: {e}", current_logs)
                return None, None
            finally:
                manager.end_task()

    def transcribe_audio(self, audio_path, output_folder, title, current_logs, lang="he"):
        final_ass = os.path.join(output_folder, f"{title}.ass")
        if os.path.exists(final_ass):
            self.log(f"âœ… ×ª××œ×•×œ ×§×™×™×.", current_logs)
            return final_ass

        self.log("â³ ×××ª×™×Ÿ ×œ××©××‘×™× ×œ×ª××œ×•×œ...", current_logs)
        with manager.semaphore:
            manager.start_task()
            try:
                self.log("ğŸ“ ××ª×—×™×œ ×ª××œ×•×œ...", current_logs)
                self.cleanup_resources()
                
                model_id = "ivrit-ai/whisper-large-v3-turbo" if lang == "he" else "openai/whisper-large-v3"
                dtype = torch.float16 if DEVICE == "cuda" else torch.float32
                pipe = pipeline("automatic-speech-recognition", model=model_id, device=DEVICE, torch_dtype=dtype, chunk_length_s=30, return_timestamps="word")
                
                clean_wav = os.path.join(output_folder, f"temp_trans_{uuid.uuid4().hex[:4]}.wav")
                self.convert_to_wav(audio_path, clean_wav)
                
                result = pipe(clean_wav, generate_kwargs={"language": "hebrew" if lang == "he" else "english"})
                self._create_ass_file(result['chunks'], final_ass, fix_hebrew=False)
                
                del pipe
                if os.path.exists(clean_wav): os.remove(clean_wav)
                self.cleanup_resources()
                return final_ass
            except Exception as e:
                self.log(f"âŒ ×©×’×™××” ×‘×ª××œ×•×œ: {e}", current_logs)
                return None
            finally:
                manager.end_task()

    def _create_ass_file(self, chunks, output_path, fix_hebrew=False):
        header = """[Script Info]\nScriptType: v4.00+\nPlayResX: 1920\nPlayResY: 1080\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Karaoke,Arial,80,&H00FFFFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,10,10,100,1\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"""
        events = []
        curr_line = []
        for chunk in chunks:
            text = chunk['text'].strip()
            if fix_hebrew: text = self._fix_hebrew_text(text)
            start, end = chunk['timestamp']
            curr_line.append({'text': text, 'start': start, 'end': end})
            
            if text.endswith(('.', '?', '!', ',')) or len(curr_line) > 6:
                l_start = self._fmt_ass_time(curr_line[0]['start'])
                l_end = self._fmt_ass_time(curr_line[-1]['end'])
                full = " ".join([w['text'] for w in curr_line])
                if fix_hebrew: full = self._fix_hebrew_text(" ".join([w['text'] for w in curr_line][::-1]))
                events.append(f"Dialogue: 0,{l_start},{l_end},Karaoke,,0,0,0,,{full}")
                curr_line = []
        
        if curr_line:
             l_start = self._fmt_ass_time(curr_line[0]['start'])
             l_end = self._fmt_ass_time(curr_line[-1]['end'])
             full = " ".join([w['text'] for w in curr_line])
             if fix_hebrew: full = self._fix_hebrew_text(full)
             events.append(f"Dialogue: 0,{l_start},{l_end},Karaoke,,0,0,0,,{full}")

        with open(output_path, "w", encoding="utf-8-sig") as f:
            f.write(header + "\n".join(events))

    def render_video(self, video_path, audio_path, ass_path, video_info, current_logs, use_bidi=False):
        folder = video_info['folder']
        title = video_info['title']
        final_video = os.path.join(folder, f"{title}_KARAOKE.mp4")
        if os.path.exists(final_video):
            self.log(f"âœ… ×¡×¨×˜×•×Ÿ ×§×™×™×.", current_logs)
            return final_video

        self.log(f"ğŸ¬ ××¨× ×“×¨...", current_logs)
        temp_ass = os.path.join(folder, "render.ass")
        try:
            with open(ass_path, 'r', encoding='utf-8-sig') as f: content = f.read()
            if use_bidi:
                lines = content.splitlines()
                new_lines = []
                for line in lines:
                    if line.startswith("Dialogue:"):
                        parts = line.split(",", 9)
                        if len(parts) == 10:
                            parts[9] = self._fix_hebrew_text(parts[9])
                            new_lines.append(",".join(parts))
                        else: new_lines.append(line)
                    else: new_lines.append(line)
                with open(temp_ass, 'w', encoding='utf-8-sig') as f: f.write("\n".join(new_lines))
            else:
                shutil.copy2(ass_path, temp_ass)
        except: return None

        ass_path_fixed = os.path.basename(temp_ass).replace("\\", "/")
        temp_out = os.path.join(folder, f"temp_{uuid.uuid4().hex[:6]}.mp4")
        cmd = [self.ffmpeg_exe, '-y', '-i', video_path, '-i', audio_path, '-filter_complex', f"[0:v]ass='{ass_path_fixed}'[v]", '-map', '[v]', '-map', '1:a', '-c:v', 'libx264', '-preset', 'ultrafast', '-c:a', 'aac', '-b:a', '192k', '-shortest', temp_out]
        
        cwd = os.getcwd(); os.chdir(folder)
        try:
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            os.chdir(cwd)
            try: os.remove(temp_ass)
            except: pass
            if os.path.exists(final_video): os.remove(final_video)
            shutil.move(temp_out, final_video)
            self.log(f"âœ… ×”×•×©×œ×: {os.path.basename(final_video)}", current_logs)
            return final_video
        except Exception as e:
            self.log(f"âŒ ×©×’×™××” ×‘×¨×™× ×“×•×¨: {e}", current_logs); os.chdir(cwd); return None

    # --- Pipeline ---
    def process_song_pipeline(self, query, lang, save_4_stems, use_bidi, force_process):
        current_logs = []
        info = self.get_video_info(query, current_logs)
        if not info: return None, "\n".join(current_logs)
        
        video_path = self.download_video(info, current_logs)
        if not video_path: return None, "\n".join(current_logs)
        
        vocals, playback = self.separate_audio(video_path, info['folder'], current_logs, save_4=save_4_stems, force=force_process)
        if not vocals or not playback: return None, "\n".join(current_logs)
        
        ass_path = self.transcribe_audio(vocals, info['folder'], info['title'], current_logs, lang)
        if not ass_path: return None, "\n".join(current_logs)
        
        if force_process:
            final_vid = os.path.join(info['folder'], f"{info['title']}_KARAOKE.mp4")
            if os.path.exists(final_vid): os.remove(final_vid)

        final = self.render_video(video_path, playback, ass_path, info, current_logs, use_bidi)
        if final: gr.Info(f"âœ… ×”×¡×ª×™×™×: {os.path.basename(final)}")
        return final, "\n".join(current_logs)

    # --- Tools ---
    def ass_to_dataframe(self, ass_path):
        if not ass_path or not os.path.exists(ass_path): return pd.DataFrame()
        data = []
        with open(ass_path, 'r', encoding='utf-8-sig') as f:
            for line in f:
                if line.startswith("Dialogue:"):
                    parts = line.split(",", 9)
                    if len(parts) == 10: data.append({"Start": parts[1], "End": parts[2], "Text": parts[9].strip()})
        return pd.DataFrame(data)

    def dataframe_to_ass(self, df, original_ass_path, output_path):
        header_lines = []
        if original_ass_path and os.path.exists(original_ass_path):
            with open(original_ass_path, 'r', encoding='utf-8-sig') as f:
                for line in f:
                    if line.startswith("Dialogue:"): break
                    header_lines.append(line)
        else:
            header_lines = ["""[Script Info]\nScriptType: v4.00+\nPlayResX: 1920\nPlayResY: 1080\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Karaoke,Arial,80,&H00FFFFFF,&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,10,10,100,1\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n"""]
        with open(output_path, 'w', encoding='utf-8-sig') as f:
            f.writelines(header_lines)
            for _, row in df.iterrows(): f.write(f"Dialogue: 0,{row['Start']},{row['End']},Karaoke,,0,0,0,,{row['Text']}\n")
        return output_path

    def update_ass_style(self, ass_path, font_size, color_hex):
        r, g, b = color_hex[1:3], color_hex[3:5], color_hex[5:7]
        ass_color = f"&H00{b}{g}{r}".upper()
        with open(ass_path, 'r', encoding='utf-8-sig') as f: content = f.read()
        new_style = f"Style: Karaoke,Arial,{int(font_size)},{ass_color},&H00FFFFFF,&H00000000,&H80000000,-1,0,0,0,100,100,0,0,1,3,0,2,10,10,100,1"
        new_content = re.sub(r"^Style:.*Karaoke.*$", new_style, content, flags=re.MULTILINE)
        with open(ass_path, 'w', encoding='utf-8-sig') as f: f.write(new_content)

    def analyze_audio(self, audio_path):
        try:
            logs = []
            self.log(f"ğŸ” ×× ×ª×—: {os.path.basename(audio_path)}...", logs)
            temp_wav = os.path.join(os.path.dirname(audio_path), f"temp_anl_{uuid.uuid4().hex[:4]}.wav")
            self.convert_to_wav(audio_path, temp_wav)
            y, sr = librosa.load(temp_wav, sr=None, duration=60)
            tempo, _ = librosa.beat.beat_track(y=y, sr=sr)
            bpm = round(float(tempo)) if np.ndim(tempo) == 0 else round(float(tempo[0]))
            chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
            key = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'][np.argmax(np.mean(chroma, axis=1))]
            if os.path.exists(temp_wav): os.remove(temp_wav)
            return f"BPM: {bpm} | Key: {key}", "\n".join(logs)
        except Exception as e: return f"Error: {e}", str(e)

    # Wrappers
    def tool_download(self, url): 
        logs = []; 
        return self.download_video(self.get_video_info(url, logs), logs), "\n".join(logs)
    
    def tool_separate(self, url, file, mode_str): 
        logs = []
        target = file.name if file else self.download_video(self.get_video_info(url, logs), logs)
        if not target: return None, "\n".join(logs)
        res = self.separate_audio(target, WORK_DIR, logs, save_4="4" in mode_str, force=True)
        return list(res) if res[0] else None, "\n".join(logs)

    def tool_transcribe(self, url, file, lang):
        logs = []
        target = file.name if file else self.download_video(self.get_video_info(url, logs), logs)
        if not target: return None, "", "\n".join(logs)
        
        vocals, _ = self.separate_audio(target, WORK_DIR, logs)
        if not vocals: return None, "", "\n".join(logs)

        ass_path = self.transcribe_audio(vocals, WORK_DIR, "Transcribed", logs, lang)
        content = ""
        if ass_path and os.path.exists(ass_path):
            with open(ass_path, 'r', encoding='utf-8-sig') as f: content = f.read()
            
        return ass_path, content, "\n".join(logs)

    def tool_analyze(self, file):
        if not file: return "No file", "No file selected"
        return self.analyze_audio(file.name)

# ==========================================
# UI
# ==========================================
backend = BackendProcessor()

def status_updater(): return manager.get_status()
def ui_process_single(url, lang, save_4_stems, use_bidi, force): return backend.process_song_pipeline(url, lang, save_4_stems, use_bidi, force)

def ui_process_batch(text_input, lang, save_4_stems, use_bidi, force):
    full_logs = []
    songs = [line.strip() for line in text_input.split('\n') if line.strip()]
    for i, song in enumerate(songs):
        full_logs.append(f"--- Processing {i+1}/{len(songs)}: {song} ---")
        res, logs = backend.process_song_pipeline(song, lang, save_4_stems, use_bidi, force)
        full_logs.append(logs)
        time.sleep(1)
    return "\n".join(full_logs)

def ui_render_dashboard(df, original_ass_file, video_file, audio_file, size, color, use_bidi):
    logs = []
    backend.log("ğŸ’¾ ××¢×‘×“ ×¢×¨×™×›×•×ª...", logs)
    temp_ass = os.path.join(WORK_DIR, f"edited_{int(time.time())}.ass")
    orig = original_ass_file.name if original_ass_file else None
    backend.dataframe_to_ass(df, orig, temp_ass)
    backend.update_ass_style(temp_ass, size, color)
    info = {'folder': WORK_DIR, 'title': f"Edited_Karaoke_{int(time.time())}"}
    v_path = video_file.name if video_file else None
    a_path = audio_file.name if audio_file else None
    final = backend.render_video(v_path, a_path, temp_ass, info, logs, use_bidi)
    return final, "\n".join(logs)

with gr.Blocks(title="Karaoke V64 Notifications", theme=gr.themes.Soft()) as app:
    gr.Markdown(f"# ğŸ¤ Karaoke Studio Pro V64 ({DEVICE.upper()})")
    
    status_label = gr.Label(value="××¢×¨×›×ª ××•×›× ×”", label="System Status")
    timer = gr.Timer(2)
    timer.tick(status_updater, None, status_label)

    with gr.Tabs():
        with gr.Tab("âš¡ ×©×™×¨ ×‘×•×“×“"):
            with gr.Row():
                with gr.Column():
                    s_url = gr.Textbox(label="×—×™×¤×•×© ××• ×œ×™× ×§")
                    s_lang = gr.Dropdown(["he", "en"], value="he", label="×©×¤×”")
                    s_4stems = gr.Checkbox(label="×©××•×¨ ×’× 4 ×¢×¨×•×¦×™×", value=False)
                    s_bidi = gr.Checkbox(label="×”×¤×•×š ×¢×‘×¨×™×ª", value=False)
                    s_force = gr.Checkbox(label="Force Reprocess", value=False)
                    s_btn = gr.Button("×”×ª×—×œ", variant="primary")
                with gr.Column():
                    s_vid = gr.Video(label="×ª×•×¦××”")
                    s_log = gr.TextArea(label="×œ×•×’×™×", lines=10)
            s_btn.click(ui_process_single, [s_url, s_lang, s_4stems, s_bidi, s_force], [s_vid, s_log])

        with gr.Tab("ğŸ“š ×¨×©×™××ª ×©×™×¨×™×"):
            b_text = gr.TextArea(label="×¨×©×™××” (×›×œ ×©×™×¨ ×‘×©×•×¨×”)")
            with gr.Row():
                b_lang = gr.Dropdown(["he", "en"], value="he", label="×©×¤×”")
                b_4stems = gr.Checkbox(label="×©××•×¨ ×’× 4 ×¢×¨×•×¦×™×", value=False)
                b_bidi = gr.Checkbox(label="×”×¤×•×š ×¢×‘×¨×™×ª", value=False)
                b_force = gr.Checkbox(label="Force Reprocess", value=False)
            b_btn = gr.Button("×”×ª×—×œ ×¨×©×™××”", variant="primary")
            b_log = gr.TextArea(label="×œ×•×’×™×", lines=20)
            b_btn.click(ui_process_batch, [b_text, b_lang, b_4stems, b_bidi, b_force], [b_log])

        with gr.Tab("ğŸ“ Dashboard"):
            with gr.Row():
                with gr.Column(scale=1):
                    d_ass = gr.File(label="ASS"); d_load = gr.Button("×˜×¢×Ÿ")
                    d_vid = gr.File(label="Video"); d_aud = gr.File(label="Playback")
                    d_size = gr.Slider(20, 150, 80, label="Size"); d_color = gr.ColorPicker("#00FFFF", label="Color")
                    d_bidi = gr.Checkbox(label="×”×¤×•×š ×¢×‘×¨×™×ª", value=False)
                    d_btn = gr.Button("×¦×•×¨")
                with gr.Column(scale=2):
                    table = gr.Dataframe(headers=["Start", "End", "Text"], datatype=["str", "str", "str"], col_count=(3, "fixed"))
                    d_res = gr.Video(); d_log = gr.TextArea()
            d_load.click(backend.ass_to_dataframe, d_ass, table)
            d_btn.click(ui_render_dashboard, [table, d_ass, d_vid, d_aud, d_size, d_color, d_bidi], [d_res, d_log])

        with gr.Tab("ğŸ› ï¸ ×›×œ×™× ××ª×§×“××™×"):
            with gr.Tabs():
                with gr.Tab("â¬‡ï¸ ×”×•×¨×“×”"):
                    dl_u = gr.Textbox(label="URL"); dl_b = gr.Button("×”×•×¨×“")
                    dl_o = gr.File(label="×§×•×‘×¥"); dl_l = gr.TextArea(label="×œ×•×’×™×")
                    dl_b.click(backend.tool_download, dl_u, [dl_o, dl_l])
                
                with gr.Tab("ğŸµ ×”×¤×¨×“×”"):
                    sp_u = gr.Textbox(label="URL"); sp_f = gr.File(label="××• ×§×•×‘×¥")
                    sp_m = gr.Radio(["2 ×¢×¨×•×¦×™×", "4 ×¢×¨×•×¦×™×"], value="2 ×¢×¨×•×¦×™×"); sp_b = gr.Button("×”×¤×¨×“")
                    sp_o = gr.Files(label="×§×‘×¦×™×"); sp_l = gr.TextArea(label="×œ×•×’×™×")
                    sp_b.click(backend.tool_separate, [sp_u, sp_f, sp_m], [sp_o, sp_l])

                with gr.Tab("ğŸ—£ï¸ ×ª××œ×•×œ"):
                    tr_u = gr.Textbox(label="URL"); tr_f = gr.File(label="××• ×§×•×‘×¥")
                    tr_lang = gr.Dropdown(["he", "en"], value="he"); tr_b = gr.Button("×ª××œ×œ")
                    tr_o = gr.File(label="ASS"); tr_txt = gr.TextArea(label="×ª×•×›×Ÿ"); tr_l = gr.TextArea(label="×œ×•×’×™×")
                    tr_b.click(backend.tool_transcribe, [tr_u, tr_f, tr_lang], [tr_o, tr_txt, tr_l])

                with gr.Tab("ğŸ” × ×™×ª×•×—"):
                    an_f = gr.File(label="×§×•×‘×¥"); an_b = gr.Button("× ×ª×—")
                    an_res = gr.Label(label="×ª×•×¦××”"); an_l = gr.TextArea(label="×œ×•×’×™×")
                    an_b.click(backend.tool_analyze, an_f, [an_res, an_l])

if __name__ == "__main__":
    app.queue(default_concurrency_limit=10).launch(inbrowser=True)
