# AI_AUDIO_LAB

AI_AUDIO_LAB is a modular, Python-based Smart DAW focused on research and experimental
AI-assisted audio workflows. The project is organized to separate the real-time audio
engine, UI, AI modules, and integrations while keeping a clear, testable architecture.

---

## Project Structure âœ…

```
AI_AUDIO_LAB/
â”œâ”€ core/                 # Audio engine, DSP building blocks
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ engine.py          # AudioEngine singleton (sounddevice wrapper)
â”œâ”€ ui/                   # PyQt6 UI widgets and main window
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ main_window.py     # MainWindow + waveform placeholder
â”œâ”€ ai_modules/           # Placeholders for Spleeter/Demucs, pitch, chords
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ (spleeter, pitch_detection, chord_gen)
â”œâ”€ integrations/         # YouTube downloads, lyrics, metadata
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ (youtube, lyrics)
â”œâ”€ utils/                # File helpers and formatting utilities
â”‚  â”œâ”€ __init__.py
â”‚  â””â”€ file_utils.py
â”œâ”€ requirements.txt      # Project dependencies
â””â”€ main.py               # Application entry point
```

---

## Quickstart ðŸš€

1. Create a Python 3.10+ virtual environment and activate it.

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Run the app:

```bash
python main.py
```

> Note: The current waveform viewer and AI modules are placeholders. The
> `AudioEngine` uses `sounddevice` with a simple pass-through callback; expect
> device-dependent behavior when starting the stream.

---

## Next Steps / Roadmap ðŸ’¡

- Replace waveform placeholder with a GPU-accelerated canvas for real-time rendering
- Add unit tests and CI
- Integrate separation (Demucs), transcription (Whisper), and advanced plugins
- Add robust audio routing, plugin host, and project/session management

---

If you'd like, I can run a quick smoke test or add a sample audio file and a minimal test harness next.
